# 3. Scale-Location (Homoskedastizität der Residuen)
# 4. Residuals vs. Hebelwerte (Einflussreiche Punkte)
boxCox(model)       # Box-Cox Transformation: prüft, ob eine Potenztransformation der Zielvariable (Preis) die Modellannahmen verbessert
# Ursprüngliche Modellformel aus dem bestehenden Modell extrahieren
final_formula <- formula(model)
# Transformation: Zielvariable (linke Seite der Formel) mit sqrt() transformieren
# z.B. aus (preis ~ x1 + x2 + ...) wird (sqrt(preis) ~ x1 + x2 + ...)
transformed_formula <- update(final_formula, sqrt(.) ~ .)
# Neues lineares Modell mit der transformierten Formel und train_df schätzen
Tmodel <- lm(formula = transformed_formula, data = train_df)
# Zusammenfassung des transformierten Modells ausgeben
summary(Tmodel)
# Alle Diagnoseplots für das transformierte Modell auf einmal anzeigen
par(mfrow = c(2, 2))   # 2x2 Layout, sodass alle vier Standard-Diagnoseplots gleichzeitig dargestellt werden
plot(Tmodel)            # Erstellt die Standard-Diagnoseplots für das lineare Modell Tmodel:
# 1. Residuen vs. Fit: prüft Nichtlinearität
# 2. Q-Q-Plot: prüft Normalität der Residuen
# 3. Scale-Location: prüft Homoskedastizität (Varianz der Residuen)
# 4. Residuals vs. Hebelwerte: identifiziert einflussreiche Beobachtungen
# 1. Datensätze in einer Liste speichern
data_list <- list(
Training_Set = train_df,  # Trainingsdaten
Test_Set     = test_df    # Testdaten
)
# 2. Funktion, die alle Schritte für einen Datensatz ausführt:
#    - Faktorstufen anpassen
#    - Vorhersagen erstellen
#    - Performance bewerten
#    - Scatterplot von vorhergesagten vs. tatsächlichen Preisen erzeugen
evaluate_and_plot <- function(df, model, name) {
# Faktorstufen anpassen: sicherstellen, dass die Levels im Datensatz mit denen im Modell übereinstimmen
model_levels <- model$xlevels
for (factor_name in names(model_levels)) {
if (factor_name %in% names(df)) {
df[[factor_name]] <- factor(df[[factor_name]], levels = model_levels[[factor_name]])
}
}
# Vorhersagen erstellen
df$predicted <- predict(model, newdata = df)
# Performance-Metriken berechnen (RMSE, R², MAE)
performance <- postResample(pred = df$predicted, obs = df$preis)
# Scatterplot von tatsächlichem vs. vorhergesagtem Preis erstellen
p <- ggplot(df, aes(x = preis, y = predicted)) +
geom_point(color = "darkblue", alpha = 0.6, size = 2) +      # Punkte
geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +  # lineare Fit-Linie
geom_abline(intercept = 0, slope = 1, color = "darkgreen", linetype = "solid", linewidth = 1) +  # perfekte Vorhersage-Linie
labs(
x = "Tatsächlicher Preis",
y = "Vorhergesagter Preis",
title = paste0("Vorhergesagter vs. tatsächlicher Preis\n(", name, " Datensatz)")
) +
theme_minimal()  # sauberes Design
return(list(performance = performance, plot = p))  # Ergebnis als Liste zurückgeben
}
# 3. Den Prozess über die Liste der Datensätze iterieren
results <- map(names(data_list), ~evaluate_and_plot(data_list[[.x]], Tmodel, .x))
names(results) <- names(data_list)
# 4. Performance-Ergebnisse extrahieren und anzeigen
performance_list <- map(results, "performance")           # Performance-Metriken extrahieren
performance_df <- as.data.frame(performance_list)         # In DataFrame umwandeln
colnames(performance_df) <- names(data_list)             # Spaltennamen setzen
print(performance_df)                                     # Performance ausgeben
# 5. Plots ausgeben
plots <- map(results, "plot")                             # Plots extrahieren
wrap_plots(plots)                                         # Plots nebeneinander oder übereinander anzeigen
# Liste der benötigten Pakete
pakete <- c(
"tidyverse",    # Sammlung von Paketen für Datenbearbeitung, -bereinigung und Visualisierung (z. B. ggplot2, dplyr, tidyr, readr, stringr, purrr)
"car",          # Werkzeuge für Regressionsanalyse, Hypothesentests und lineare Modelle
"corrplot",     # Grafische Darstellung von Korrelationsmatrizen (z. B. Heatmaps von Zusammenhängen)
"broom",        # Statistische Modellergebnisse in saubere Tabellenform überführen (tidy output)
"stringr",      # Arbeiten mit Zeichenketten (Strings), z. B. Textsuche, Ersetzen, Formatierung
"purrr",        # Funktionale Programmierung (Iteration mit map-Funktionen statt Schleifen)
"caret",        # Machine-Learning-Framework für Klassifikation und Regression (inkl. Cross-Validation)
"patchwork",    # Kombinieren mehrerer ggplot2-Grafiken zu einem Layout
"MASS",         # Statistische Methoden und Datensätze (z. B. Schrittweise Regression, Verteilungen)
"leaps"         # Variablenselektion in Regressionsmodellen (subset selection)
)
# Funktion zum Installieren und Laden fehlender Pakete
installiere_und_lade_wenn_nicht_vorhanden <- function(pkg) {
if (!requireNamespace(pkg, quietly = TRUE)) {   # Prüfen, ob Paket vorhanden ist
install.packages(pkg)                        # Falls nicht installiert: automatisch von CRAN holen
}
library(pkg, character.only = TRUE)            # Laden (Paketname als Zeichenkette übergeben)
}
# Alle Pakete installieren und laden
lapply(pakete, installiere_und_lade_wenn_nicht_vorhanden)
# Daten importieren
cars_df <- read_csv("C:\\Users\\cleme\\Desktop\\Projekte\\Auto-Preis-Prediktion\\Daten\\cars.csv")
# Datenexploration
# View(cars_df)
head(cars_df, n=10)
cars_df$...1  <- NULL
cars_df[duplicated(cars_df),]
# Übersicht aller Spalten
summary(cars_df)   # Statistische Übersicht (Min, Max, Mittelwert, NA-Zahlen etc.) pro Spalte
# Kategoriale Spalten identifizieren
kategorielle_spalten <- !sapply(cars_df, is.numeric)   # TRUE für nicht-numerische Spalten (z. B. Strings, Faktoren)
# Häufigkeitstabellen für kategoriale Spalten erstellen
sapply(cars_df[kategorielle_spalten], table)   # Gibt für jede kategoriale Spalte die Häufigkeit der Werte zurück
cars_df[cars_df == "?"] <- "NA"          # Alle Zellen mit "?" durch "NA" ersetzen (für fehlende Werte)
cars_df[cars_df == "std"] <- "standard"  # Kürzel "std" durch "standard" ersetzen (vereinheitlichen)
## Datenstruktur anschauen
str(cars_df)
cars_df <- cars_df %>%                                                 # Startet eine Daten-Transformation mit dem Pipe-Operator (%>%)
mutate(                                                              # Öffnet mutate(), um neue Werte zu berechnen bzw. Spalten zu ändern
anzahl_zylinder    = dplyr::recode(anzahl_zylinder,                # Ersetzt Textwerte in 'anzahl_zylinder' durch Ziffern als Strings
"four" = "4",                          # "four" → "4"
"six" = "6",                           # "six"  → "6"
"five" = "5",                          # "five" → "5"
"three" = "3",                         # "three" → "3"
"twelve" = "12",                       # "twelve" → "12"
"two" = "2",                           # "two" → "2"
"eight" = "8"),                        # "eight" → "8"
anzahl_zylinder    = as.integer(anzahl_zylinder),                  # Wandelt die recodierten Strings in Ganzzahlen (Integer) um
tueren             = dplyr::recode(tueren,                         # Ersetzt Textwerte in 'tueren' durch Ziffern als Strings
"two" = "2",                           # "two" → "2"
"four" ="4",                           # "four" → "4"
"NA" = "NA"),                            # Lässt unbekannte Werte ("?") unverändert
tueren             = as.integer(tueren),                           # Wandelt 'tueren' in Ganzzahlen um (NA für nicht konvertierbare Werte)
kolben_durchmesser = as.double(kolben_durchmesser),                # Wandelt 'kolben_durchmesser' in numerischen Typ double um
stroke             = as.double(stroke),                            # Wandelt 'stroke' in double um
PS                 = as.double(PS),                                # Wandelt 'PS' in double um
drehzahl_max       = as.double(drehzahl_max),                       # Wandelt 'drehzahl_max' in double um
preis              = as.double(preis)                              # Wandelt 'preis' in double um
)
str(cars_df)                                                           # Zeigt die Struktur des Dataframes inkl. neuer Spaltentypen
# Eine Tabelle der fehlenden Werte erstellen
fehlende_Werte <- as.data.frame(colSums(is.na(cars_df)))   # Anzahl fehlender Werte pro Spalte zählen und als DataFrame speichern
colnames(fehlende_Werte) <- "Anzahl_Fehlende_Werte"        # Spaltennamen setzen
# Relative Häufigkeit berechnen
fehlende_Werte$Haeufigkeit_Prozent <- round((fehlende_Werte$Anzahl_Fehlende_Werte / nrow(cars_df)) * 100, 2)   # Anteil fehlender Werte in %
# Sortieren der Tabelle nach Anzahl der fehlenden Werte (absteigend)
fehlende_Werte <- fehlende_Werte %>% arrange(desc(Anzahl_Fehlende_Werte))   # Sortieren: Spalten mit den meisten NAs zuerst
# Die sortierte Tabelle anzeigen
head(fehlende_Werte, n = 8)   # Ausgabe der Top-8 Spalten mit den meisten fehlenden Werten
colSums(is.na(cars_df))                             # Zählt, wie viele NA-Werte in jeder Spalte vorkommen
cars_df <- cars_df[rowSums(is.na(cars_df)) == 0, ]  # Behalte nur Zeilen ohne fehlende Werte (löscht alle mit >=1 NA)
cat("\n\n")                                         # Fügt zwei Leerzeilen in der Konsolenausgabe ein (bessere Lesbarkeit)
colSums(is.na(cars_df))                             # Prüft erneut, ob nach dem Entfernen noch NA-Werte vorhanden sind
#  Funktion zur Ermittlung der Ausreißer-Indizes nach der IQR-Methode
find_outliers_iqr <- function(x) {
Q1 <- quantile(x, 0.25,na.rm =TRUE)          # 1. Quartil (25%-Perzentil) berechnen
Q3 <- quantile(x, 0.75, na.rm= TRUE)         # 3. Quartil (75%-Perzentil) berechnen
IQR <- Q3 - Q1                               # Interquartilsabstand (Q3 minus Q1)
lower <- Q1 - 1.5 * IQR                      # untere Grenze für Ausreißer bestimmen
upper <- Q3 + 1.5 * IQR                      # obere Grenze für Ausreißer bestimmen
which(x < lower | x > upper)                 # Indizes der Werte zurückgeben, die außerhalb der Grenzen liegen
}
#  Hilfsfunktion: numerische Spalten extrahieren und Ausreißer pro Spalte zählen
get_outlier_counts <- function(df) {
numeric_cols <- sapply(df, is.numeric)               # logischer Vektor: welche Spalten sind numerisch?
numeric_df <- df[, numeric_cols]                     # nur die numerischen Spalten auswählen
outlier_indices <- lapply(numeric_df, find_outliers_iqr)  # für jede Spalte Ausreißer-Indizes ermitteln
sapply(outlier_indices, length)                      # Anzahl der Ausreißer pro Spalte zurückgeben
}
# Ausreißer  zählen
outlier_counts <- get_outlier_counts(cars_df)  # Hilfsfunktion auf den ursprünglichen Dataframe anwenden
print(outlier_counts)                          # Anzahl der Ausreißer pro Spalte vor der Ersetzung ausgeben
cat("\n\n")                                    # zwei Leerzeilen einfügen, um die Ausgaben zu trennen
#  Ausreißer durch untere/obere Grenze ersetzen
numeric_cols <- sapply(cars_df, is.numeric)                # Prüfen, welche Spalten numerisch sind
for (colname in names(cars_df)[numeric_cols]) {            # Jede numerische Spalte durchgehen
vec <- cars_df[[colname]]                                # Spaltenvektor extrahieren
if (colname == "anzahl_zylinder") {                      # Sonderfall: Variable "anzahl_zylinder"
lower <- quantile(vec, 0.10, na.rm = TRUE)             # Unteres 10%-Perzentil als Grenze
upper <- quantile(vec, 0.90, na.rm = TRUE)             # Oberes 90%-Perzentil als Grenze
} else {                                                 # Standardfall: alle anderen numerischen Spalten
Q1 <- quantile(vec, 0.25, na.rm = TRUE)                # 1. Quartil (25%)
Q3 <- quantile(vec, 0.75, na.rm = TRUE)                # 3. Quartil (75%)
IQR <- Q3 - Q1                                         # Interquartilsabstand
lower <- Q1 - 1.5 * IQR                                # Untere Grenze (IQR-Regel)
upper <- Q3 + 1.5 * IQR                                # Obere Grenze (IQR-Regel)
}
vec[vec < lower] <- lower                                # Werte kleiner als die untere Grenze → auf Grenze setzen
vec[vec > upper] <- upper                                # Werte größer als die obere Grenze → auf Grenze setzen
cars_df[[colname]] <- vec                                # Bereinigten Vektor zurückschreiben
}
# Ausreißer zur Prüfung nach dem Ersetzen zählen
outlier_counts <- get_outlier_counts(cars_df)              # Benutzerdefinierte Funktion: zählt verbleibende Ausreißer
print(outlier_counts)                                      # Ausgabe: Anzahl Ausreißer pro Spalte
cat("\n\n")                                                # Zwei Leerzeilen für bessere Lesbarkeit
# Numerische Spalten extrahieren
num_cols <- sapply(cars_df, is.numeric)           # Prüft für jede Spalte, ob sie numerisch ist, Ergebnis: logischer Vektor
numeric_df <- cars_df[, num_cols]                 # Wählt nur die numerischen Spalten aus dem Dataframe aus
# Für jede numerische Spalte: Summary, Boxplot, Histogramm, Density Plot
for (col_name in names(numeric_df)) {             # Schleife über alle Spaltennamen der numerischen Spalten
data_vector <- numeric_df[[col_name]]           # Extrahiert die Spalte als Vektor
# Nur mit vollständigen Werten arbeiten (für density)
data_vector <- data_vector[!is.na(data_vector)] # Entfernt fehlende Werte (NAs) aus dem Vektor
# Layout: 1 Zeile, 4 Spalten
par(mfrow = c(1, 4))                            # Setzt das Plot-Layout auf 1 Zeile, 4 Spalten
# 1. Summary-Statistik + Standardabweichung
plot.new()                                      # Öffnet einen neuen, leeren Plot (für Textausgabe)
summary_stats <- summary(data_vector)           # Berechnet Min, 1.Quartil, Median, Mittelwert, 3.Quartil, Max
std_dev <- sd(data_vector)                      # Berechnet die Standardabweichung
IQR<- quantile(data_vector,0.75)-quantile(data_vector,0.25) # Berechnet den Interquartilsabstand
# Titel
title_text <- paste("Summary")
text(x = 0, y = 1, labels = title_text, adj = 0, font = 2, cex = 1.6)   # Zeichnet den Titel im Plot (links oben, fett, größere Schrift)
# Zeilenweise Ausgabe
y_pos <- 0.9                                    # Startposition für den Text (etwas unter dem Titel)
line_spacing <- 0.1                             # Abstand zwischen den Textzeilen
for (i in seq_along(summary_stats)) {           # Schleife über alle Summary-Werte
label <- names(summary_stats)[i]              # Label (z.B. "Min.", "Median")
value <- round(summary_stats[i], 2)           # Wert auf 2 Dezimalstellen runden
text_line <- paste0(label, ": ", value)       # Textzeile zusammenbauen
text(x = 0, y = y_pos, labels = text_line, adj = 0, cex = 1.3)  # Text in Plot schreiben (linksbündig, größere Schrift)
y_pos <- y_pos - line_spacing                 # Y-Position für nächste Zeile nach unten verschieben
}
# Standardabweichung anzeigen
text(x = 0, y = y_pos, labels = paste0("SD: ", round(std_dev, 2)), adj = 0, cex = 1.3)  # SD unten anhängen (größere Schrift)
y_pos <- y_pos - line_spacing                    # Abstand zwischen den Textzeilen
# Interquartilsabstände anzeigen
text(x = 0, y = y_pos, labels = paste0("IQR: ", round(IQR, 2)), adj = 0, cex = 1.3)  # IQR unten anhängen (größere Schrift)
# 2. Boxplot
boxplot(data_vector,
main = paste("Boxplot:", col_name),     # Titel mit Spaltenname
ylab = col_name)                        # Y-Achsen-Beschriftung
# 3. Histogramm
hist(data_vector,
main = paste("Histogramm:", col_name),     # Titel
xlab = col_name,                           # X-Achsen-Beschriftung
col = "lightblue",                         # Balkenfarbe
border = "black")                          # Rahmenfarbe der Balken
# 4. Density Plot
dens <- density(data_vector)                    # Dichtefunktion schätzen
plot(dens,
main = paste("Density Plot:", col_name),   # Titel
xlab = col_name,                           # X-Achsen-Beschriftung
col = "darkgreen",                         # Linienfarbe
lwd = 2)                                   # Linienbreite
polygon(dens, col = rgb(0, 1, 0, 0.3), border = "darkgreen")  # Fläche unter der Dichte halbtransparent ausfüllen
}
# Nicht-numerische Spalten extrahieren
num_cols <- sapply(cars_df, is.numeric)               # Logischer Vektor: TRUE für numerische Spalten
char_df <- cars_df[, !num_cols]                       # Wählt nur die nicht-numerischen Spalten aus
# Für jede nicht-numerische Spalte: Summary, Barplot, Häufigkeitstabelle
for (col_name in names(char_df)) {                    # Schleife über alle nicht-numerischen Spaltennamen
data_vector <- as.factor(char_df[[col_name]])       # Spalte als Faktor behandeln (Kategorien)
# Layout: 1 Zeile, 3 Spalten
par(mfrow = c(1, 3))                                # Plot-Layout auf 1 Zeile, 3 Spalten setzen
# 1. Summary-Statistik (Textfeld)
plot.new()                                          # Neuer leerer Plot für Textausgabe
title_text <- paste("Summary")                      # Titeltext mit Spaltennamen erzeugen
text(x = 0, y = 1, labels = title_text, adj = 0, font = 2,cex = 1.3)  # Titel links oben, fett
y_pos <- 0.9                                        # Start-Y-Position für Text unter Titel
line_spacing <- 0.1                                 # Abstand zwischen Textzeilen
# Anzahl Kategorien
n_levels <- length(levels(data_vector))             # Anzahl eindeutiger Kategorien bestimmen
text(x = 0, y = y_pos, labels = paste0("Anzahl Kategorien: ", n_levels), adj = 0,cex = 1.3) # Ausgabe Anzahl Kategorien
y_pos <- y_pos - line_spacing                       # Y-Position nach unten verschieben
# Häufigste Kategorie
freq_table <- table(data_vector)                     # Häufigkeitstabelle der Kategorien erstellen
sorted_freq <- sort(freq_table, decreasing = TRUE)   # Tabelle absteigend nach Häufigkeit sortieren
top_level <- names(sorted_freq)[1]                   # Name der häufigsten Kategorie
top_freq <- sorted_freq[1]                           # Häufigkeit der häufigsten Kategorie
text(x = 0, y = y_pos, labels = paste0("Häufigste Kategorie: ", top_level, " (", top_freq, ")"), adj = 0,cex = 1.3) # Ausgabe
# 2. Barplot (auch sortiert)
barplot(sorted_freq,                                 # Barplot der Häufigkeiten zeichnen
main = paste("Barplot:", col_name),          # Titel mit Spaltennamen
las = 2,                                     # Drehung der Achsenbeschriftung (senkrecht)
col = "lightblue",                           # Balkenfarbe
border = "black",                            # Balkenumrandung
cex.names = 1)                             # Schriftgröße der Balkennamen
# 3. Häufigkeitstabelle als Text (sortiert, relativ + absolut)
plot.new()                                          # Neuer leerer Plot für Textausgabe
total <- sum(freq_table)                            # Gesamtanzahl Beobachtungen (ohne NA)
rel_freq <- round(100 * sorted_freq / total, 1)     # Relative Häufigkeit in Prozent, gerundet
text(x = 0, y = 1, labels = "Häufigkeiten", adj = 0, font = 2,cex = 1.3)  # Überschrift
y_pos <- 0.9                                        # Startposition für die Häufigkeiten
max_display <- min(length(sorted_freq), 8)          # Maximal 8 Kategorien anzeigen
for (i in 1:max_display) {                          # Schleife für die Top-Kategorien
label <- names(sorted_freq)[i]                    # Kategorie-Name
abs_val <- sorted_freq[i]                         # Absolute Häufigkeit
rel_val <- rel_freq[i]                            # Relative Häufigkeit
text_line <- paste0(label, ": ", abs_val, " (", rel_val, "%)")  # Text zusammensetzen
text(x = 0, y = y_pos, labels = text_line, adj = 0, cex = 1.3) # Text ausgeben
y_pos <- y_pos - line_spacing                      # Y-Position weiter nach unten verschieben
}
if (length(sorted_freq) > max_display) {            # Wenn mehr Kategorien vorhanden sind als angezeigt
text(x = 0, y = y_pos, labels = "... (weitere Kategorien)", adj = 0,cex = 1.3)  # Hinweis ausgeben
}
# Layout zurücksetzen
par(mfrow = c(1, 1))                                # Plot-Layout auf Standard zurücksetzen
}
numeric_df <- cars_df[, sapply(cars_df, is.numeric)]          # Nur numerische Spalten aus cars_df auswählen
target <- "preis"                                             # Zielvariable definieren
predictors <- numeric_df[, names(numeric_df) != target]       # Alle numerischen Spalten außer "preis" als Prädiktoren
long_df <- cbind(preis = numeric_df[[target]], predictors) %>% # preis-Spalte mit Prädiktoren zusammenfügen
as.data.frame() %>%                                          # sicherstellen, dass es ein Dataframe ist
pivot_longer(cols = -preis, names_to = "Predictor",          # alle Spalten außer preis stapeln
values_to = "Value")                           # neue Spalten: "Predictor" = Name, "Value" = Wert
ggplot(long_df, aes(x = Value, y = preis)) +                   # Datenquelle: long_df, Achsen: Value (x), preis (y)
geom_point() +                                               # Punkte zeichnen
facet_wrap(~ Predictor, scales = "free_x") +                 # für jeden Predictor eigenes Panel mit eigener x-Achse
labs(x = NULL, y = "preis",                                  # Achsenbeschriftung und Titel
title = "Scatterplots: Preis vs Prädiktoren") +
theme_minimal()                                              # minimalistisches Layout
# 1. Nur numerische Spalten extrahieren
cars_df <- cars_df %>% na.omit()              # Entfernt alle Zeilen mit mindestens einem NA-Wert,falls vorhanden
num_cols <- sapply(cars_df, is.numeric)       # Prüft jede Spalte: TRUE, wenn numerisch, sonst FALSE
numeric_df <- cars_df[, num_cols]             # Selektiert nur die numerischen Spalten aus cars_df
# 2. Korrelationsmatrix berechnen
cor_matrix <- cor(numeric_df)                 # Berechnet die Pearson-Korrelationen zwischen allen numerischen Spalten
# 3. Mixed Corrplot erzeugen
corrplot.mixed(cor_matrix)                    # Visualisiert die Korrelationsmatrix:
# obere Hälfte als Kreise (grafisch), untere Hälfte als Zahlen (genauer Wert)
# 1. Nicht-numerische Spalten extrahieren (ohne Preis)
non_numeric_cols <- !sapply(cars_df, is.numeric)   # TRUE für nicht-numerische Spalten
cat_df <- cars_df[, non_numeric_cols]              # Selektiert nur diese Spalten
# 2. Preis-Spalte
preis_vector <- cars_df$preis                      # Vektor mit den Preisen
# Anzahl der kategorialen Variablen
n_cols <- ncol(cat_df)                             # Anzahl Spalten in cat_df
# Layout vorbereiten (z. B. 2 Zeilen, 3 Spalten)
par(mfrow = c(ceiling(n_cols/3), 3), mar=c(5,4,4,2))  # Anzahl Zeilen automatisch, 3 Boxplots pro Reihe, Ränder setzen
# 3. Schleife für jede kategoriale Variable
for (col_name in names(cat_df)) {
kategorie <- as.factor(cat_df[[col_name]])       # Spalte in Faktor umwandeln
if (length(unique(na.omit(kategorie))) > 1) {   # Nur Variablen mit >1 Kategorie bearbeiten
# Median pro Kategorie berechnen
median_preis <- tapply(preis_vector, kategorie, median, na.rm = TRUE)
# Kategorien nach Median sortieren (höchster Median zuerst)
sorted_levels <- names(sort(median_preis, decreasing = TRUE))   # Namen der Kategorien nach Median-Wert sortieren, absteigend
kategorie <- factor(kategorie, levels = sorted_levels)          # Faktorlevels entsprechend der sortierten Reihenfolge anpassen
median_preis <- median_preis[sorted_levels]                     # Median-Werte in der gleichen Reihenfolge anordnen
# Boxplot erstellen
boxplot(preis_vector ~ kategorie,
main = paste("Preis vs", col_name),   # Titel
xlab = "",                             # x-Achse leer
ylab = "Preis",                        # y-Achsenbeschriftung
col = "lightblue",                      # Füllfarbe Boxplot
las = 2,                                # x-Achsenbeschriftung senkrecht
cex.axis = 0.7)                         # Schriftgröße Achsenbeschriftung
# Medianpunkte hinzufügen
points(1:length(median_preis), median_preis, col = "red", pch = 19)  # Rote Punkte für Mediane
# Linie durch Medianpunkte
lines(1:length(median_preis), median_preis, col = "red", lwd = 2)    # Linie verbindet die Mediane
}
}
cars_df <- cars_df %>%
dplyr::mutate(
# Hersteller in Gruppen zusammenfassen
hersteller = case_when(
hersteller %in% c("jaguar", "mercedes-benz", "porsche", "bmw") ~ "LS",        # Luxussegment
hersteller %in% c("volvo", "audi", "peugot", "mercury", "alfa-romero", "saab", "volkswagen") ~ "MS",  # Mittlere Segment
hersteller %in% c("toyota", "isuzu", "mazda", "mitsubishi", "nissan", "subaru",
"plymouth", "honda", "dodge", "chevrolet") ~ "NS",           # Niedriges Segment
TRUE ~ NA_character_                                                           # Alle anderen/fehlenden Werte als NA
),
# Kraftstoffsystem gruppieren
kraftstoff_system = case_when(
kraftstoff_system %in% c("mpfi", "idi") ~ "mpfi_idi",                          # Gruppe 1
kraftstoff_system %in% c("mfi", "spfi", "spdi") ~ "mfi_spfi_spdi",             # Gruppe 2
kraftstoff_system %in% c("2bbl", "1bbl") ~ "2bbl_1bbl",                        # Gruppe 3
TRUE ~ NA_character_                                                           # Alle anderen/fehlenden Werte als NA
),
# Karosserieform gruppieren
karosserie_form = case_when(
karosserie_form %in% c("hardtop","convertible") ~ "hardtop_convertible",      # Sportliche Karosserien
karosserie_form %in% c("wagon","sedan") ~ "wagon_sedan",                      # Familienautos
karosserie_form %in% c("hatchback") ~ "hatchback",                            # Einzelgruppe Hatchback
TRUE ~ NA_character_                                                          # Alle anderen/fehlenden Werte als NA
),
# Motorsteuerung gruppieren
motorsteuerung = case_when(
motorsteuerung %in% c("ohcv") ~ "ohcv",                                       # Einzelgruppe
motorsteuerung %in% c("dohc","l") ~ "dohc_l",                                 # Gruppe 1
motorsteuerung %in% c("ohcf","ohc") ~ "ohcf_ohc",                             # Gruppe 2
TRUE ~ NA_character_                                                          # Alle anderen/fehlenden Werte als NA
),
# Antriebsart separat gruppieren
antrieb_typ = case_when(
antrieb_typ %in% c("rwd") ~ "nwd",                                            # Hinterradantrieb
antrieb_typ %in% c("fwd", "4wd") ~ "4wd_fwd",                                 # Front- oder Allradantrieb
TRUE ~ NA_character_                                                          # Alle anderen/fehlenden Werte als NA
)
)
# 1. Nicht-numerische Spalten extrahieren (ohne Preis)
non_numeric_cols <- !sapply(cars_df, is.numeric)   # TRUE für nicht-numerische Spalten
cat_df <- cars_df[, non_numeric_cols]              # Nur diese Spalten auswählen
# 2. Preis-Spalte
preis_vector <- cars_df$preis                      # Vektor mit den Preisen
# 3. Anzahl Plots und Layout berechnen
num_plots <- ncol(cat_df)                          # Anzahl der kategorialen Variablen
rows <- ceiling(sqrt(num_plots))                   # Anzahl Zeilen: quadratische Anordnung für Übersicht
cols <- ceiling(num_plots / rows)                  # Anzahl Spalten automatisch berechnen
par(mfrow = c(rows, cols), mar = c(5,5,4,2))       # Plot-Layout setzen: mfrow und Ränder
# 4. Schleife für jede kategoriale Variable
for (col_name in names(cat_df)) {
kategorie <- as.factor(cat_df[[col_name]])      # Spalte in Faktor umwandeln
if (length(unique(na.omit(kategorie))) > 1) {   # Nur Variablen mit mehr als 1 Kategorie bearbeiten
# Median pro Kategorie berechnen
median_preis <- tapply(preis_vector, kategorie, median, na.rm = TRUE)
# Kategorien nach Median sortieren (höchster Median zuerst)
sorted_levels <- names(sort(median_preis, decreasing = TRUE))
kategorie <- factor(kategorie, levels = sorted_levels)
median_preis <- median_preis[sorted_levels]
# Boxplot erstellen
boxplot(preis_vector ~ kategorie,
main = paste("Boxplot von Preis vs", col_name),  # Titel dynamisch
xlab = col_name,                                 # x-Achsenbeschriftung
ylab = "Preis",                                  # y-Achsenbeschriftung
col = "lightblue",                               # Füllfarbe
las = 2)                                         # x-Achse senkrecht
# Medianpunkte hinzufügen
points(1:length(median_preis), median_preis, col = "red", pch = 19)  # rote Punkte für Mediane
# Linie durch Medianpunkte
lines(1:length(median_preis), median_preis, col = "red", lwd = 2)    # rote Linie durch Mediane
}
}
# Layout zurücksetzen
par(mfrow = c(1,1))  # Standard-Plotlayout wiederherstellen
set.seed(120)                                                 # Zufallssamen setzen, damit Ergebnisse reproduzierbar sind
#  Numerische Spalten auswählen
numeric_vars <- c("breite", "anzahl_zylinder",            # Numerische Prädiktoren, die ausreichend stark mit der Zielvariable "preis" korrelieren (r > 0.2)
"motor_groesse", "kolben_durchmesser",  # und untereinander keine hohe Multikollinearität aufweisen (r < 0.8)
"verbrauch_autobahn_mpg", "preis")
# Kategorische Spalten auswählen (Beispiel)
categorical_vars <- names(cars_df)[!sapply(cars_df, is.numeric)]  # Alle Spalten, die nicht numerisch sind
# Dataframe mit ausgewählten Spalten erstellen
cars_df_select <- cars_df[, c(categorical_vars, numeric_vars)]    # Nur die ausgewählten Spalten behalten
#  Train/Test-Split
train_ratio <- 0.8                                             # Anteil der Daten für Training (80%)
n <- nrow(cars_df_select)                                      # Gesamtanzahl der Zeilen
train_indices <- sample(1:n, size = floor(train_ratio * n))    # Zufällige Auswahl von Trainings-Indizes
train_df <- cars_df_select[train_indices, ]                    # Trainingsdaten zusammenstellen
test_df  <- cars_df_select[-train_indices, ]                   # Testdaten aus den verbleibenden Zeilen
# 1. Start-Modell (Start mit allen Variablen)
full_model <- lm(preis ~ ., data = train_df)   # Lineares Modell mit allen Prädiktoren in train_df
# 2. Leeres Modell (Start ohne Variablen)
empty_model <- lm(preis ~ 1, data = train_df)  # Modell nur mit Intercept (kein Prädiktor)
# Startpunkt für Forward-Selection
# 3. Stepwise-Regression durchführen (kombinierte Auswahl)
model <- stepAIC(
full_model,                                 # Startmodell für die Selektion
scope = list(lower = empty_model, upper = full_model),  # Definiert Minimal- und Maximalmodell
direction = "both",                          # Sowohl Forward- als auch Backward-Selection
trace = 1                                    # Ausgabe der Zwischenschritte
)
summary(model)                                 # Zusammenfassung des final ausgewählten Modells
# Alle Diagnoseplots auf einmal anzeigen
par(mfrow = c(2, 2))   # 2x2 Layout, sodass alle vier Standard-Diagnoseplots gleichzeitig angezeigt werden
plot(model)            # Erstellt die Standard-Diagnoseplots für ein lineares Modell:
# 1. Residuen vs. Fit (Prüfung auf Nichtlinearität)
# 2. Q-Q-Plot (Normalität der Residuen)
# 3. Scale-Location (Homoskedastizität der Residuen)
# 4. Residuals vs. Hebelwerte (Einflussreiche Punkte)
boxCox(model)       # Box-Cox Transformation: prüft, ob eine Potenztransformation der Zielvariable (Preis) die Modellannahmen verbessert
# Ursprüngliche Modellformel aus dem bestehenden Modell extrahieren
final_formula <- formula(model)
# Transformation: Zielvariable (linke Seite der Formel) mit sqrt() transformieren
# z.B. aus (preis ~ x1 + x2 + ...) wird (sqrt(preis) ~ x1 + x2 + ...)
transformed_formula <- update(final_formula, sqrt(.) ~ .)
# Neues lineares Modell mit der transformierten Formel und train_df schätzen
Tmodel <- lm(formula = transformed_formula, data = train_df)
# Zusammenfassung des transformierten Modells ausgeben
summary(Tmodel)
# Alle Diagnoseplots für das transformierte Modell auf einmal anzeigen
par(mfrow = c(2, 2))   # 2x2 Layout, sodass alle vier Standard-Diagnoseplots gleichzeitig dargestellt werden
plot(Tmodel)            # Erstellt die Standard-Diagnoseplots für das lineare Modell Tmodel:
# 1. Residuen vs. Fit: prüft Nichtlinearität
# 2. Q-Q-Plot: prüft Normalität der Residuen
# 3. Scale-Location: prüft Homoskedastizität (Varianz der Residuen)
# 4. Residuals vs. Hebelwerte: identifiziert einflussreiche Beobachtungen
# 1. Datensätze in einer Liste speichern
data_list <- list(
Training_Set = train_df,  # Trainingsdaten
Test_Set     = test_df    # Testdaten
)
# 2. Funktion, die alle Schritte für einen Datensatz ausführt:
#    - Faktorstufen anpassen
#    - Vorhersagen erstellen
#    - Performance bewerten
#    - Scatterplot von vorhergesagten vs. tatsächlichen Preisen erzeugen
evaluate_and_plot <- function(df, model, name) {
# Faktorstufen anpassen: sicherstellen, dass die Levels im Datensatz mit denen im Modell übereinstimmen
model_levels <- model$xlevels
for (factor_name in names(model_levels)) {
if (factor_name %in% names(df)) {
df[[factor_name]] <- factor(df[[factor_name]], levels = model_levels[[factor_name]])
}
}
# Vorhersagen erstellen
df$predicted <- predict(model, newdata = df)
# Performance-Metriken berechnen (RMSE, R², MAE)
performance <- postResample(pred = df$predicted, obs = df$preis)
# Scatterplot von tatsächlichem vs. vorhergesagtem Preis erstellen
p <- ggplot(df, aes(x = preis, y = predicted)) +
geom_point(color = "darkblue", alpha = 0.6, size = 2) +      # Punkte
geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +  # lineare Fit-Linie
geom_abline(intercept = 0, slope = 1, color = "darkgreen", linetype = "solid", linewidth = 1) +  # perfekte Vorhersage-Linie
labs(
x = "Tatsächlicher Preis",
y = "Vorhergesagter Preis",
title = paste0("Vorhergesagter vs. tatsächlicher Preis\n(", name, " Datensatz)")
) +
theme_minimal()  # sauberes Design
return(list(performance = performance, plot = p))  # Ergebnis als Liste zurückgeben
}
# 3. Den Prozess über die Liste der Datensätze iterieren
results <- map(names(data_list), ~evaluate_and_plot(data_list[[.x]], Tmodel, .x))
names(results) <- names(data_list)
# 4. Performance-Ergebnisse extrahieren und anzeigen
performance_list <- map(results, "performance")           # Performance-Metriken extrahieren
performance_df <- as.data.frame(performance_list)         # In DataFrame umwandeln
colnames(performance_df) <- names(data_list)             # Spaltennamen setzen
print(performance_df)                                     # Performance ausgeben
# 5. Plots ausgeben
plots <- map(results, "plot")                             # Plots extrahieren
wrap_plots(plots)                                         # Plots nebeneinander oder übereinander anzeigen
